# -*- coding: utf-8 -*-
"""Data Prep report.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mvXHPOqd3B5XucO0Ud5i70lCYM1kLJSN

# Import necessary **libraries**
"""

# Commented out IPython magic to ensure Python compatibility.

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Set visualizations to appear inline
# %matplotlib inline

"""# Upload the Excel file"""

from google.colab import files
uploaded = files.upload()

"""# Load the Excel file"""

excel_file = 'global_superstore_2016.xlsx'

# Load each sheet into a separate DataFrame
orders_df = pd.read_excel(excel_file, sheet_name='Orders')
people_df = pd.read_excel(excel_file, sheet_name='People')
returns_df = pd.read_excel(excel_file, sheet_name='Returns')

"""# Basic Information about each sheet"""

# Display basic information about Orders DataFrame
print("Orders DataFrame Info:")
print(orders_df.info())
print("\nFirst 5 Rows of Orders DataFrame:")
print(orders_df.head())

# Display basic information about People DataFrame
print("\nPeople DataFrame Info:")
print(people_df.info())
print("\nFirst 5 Rows of People DataFrame:")
print(people_df.head())

# Display basic information about Returns DataFrame
print("\nReturns DataFrame Info:")
print(returns_df.info())
print("\nFirst 5 Rows of Returns DataFrame:")
print(returns_df.head())

"""# Shape of the Dataset"""

# Check the number of records and columns in each DataFrame
print("Orders DataFrame Shape:", orders_df.shape)
print("People DataFrame Shape:", people_df.shape)
print("Returns DataFrame Shape:", returns_df.shape)

"""# Missing Values"""

# Check for missing values in Orders DataFrame
missing_values_orders = orders_df.isnull().sum()
missing_percentage_orders = (orders_df.isnull().sum() / len(orders_df)) * 100
missing_data_orders = pd.DataFrame({
    'Missing Values': missing_values_orders,
    'Percentage (%)': missing_percentage_orders
})
print("Missing Values in Orders DataFrame:")
print(missing_data_orders)

# Visualize missing data using a heatmap
plt.figure(figsize=(12, 6))
sns.heatmap(orders_df.isnull(), cbar=False, cmap='viridis')
plt.title('Missing Values Heatmap - Orders DataFrame')
plt.show()

# Drop 'Postal Code' column from Orders DataFrame
orders_df_cleaned = orders_df.drop(columns=['Postal Code'])
print("Dropped 'Postal Code' column. New shape:", orders_df_cleaned.shape)

"""# Checking For Duplicates"""

# Check for duplicate Order IDs in Orders DataFrame
duplicate_order_ids = orders_df_cleaned.duplicated(subset=['Order ID'])
num_duplicate_order_ids = duplicate_order_ids.sum()
print(f"Number of duplicate Order IDs in Orders DataFrame: {num_duplicate_order_ids}")

# If duplicates exist, view them
if num_duplicate_order_ids > 0:
    print("Duplicate Order IDs:")
    print(orders_df_cleaned[orders_df_cleaned.duplicated(subset=['Order ID'], keep=False)].sort_values('Order ID'))

# Check for entire row duplicates
duplicate_rows = orders_df_cleaned.duplicated()
num_duplicate_rows = duplicate_rows.sum()
print(f"Number of duplicate rows in Orders DataFrame: {num_duplicate_rows}")

# Remove duplicate rows if any
if num_duplicate_rows > 0:
    orders_df_cleaned = orders_df_cleaned.drop_duplicates()
    print(f"Dropped {num_duplicate_rows} duplicate rows. New shape:", orders_df_cleaned.shape)

# Check for duplicate Order IDs in Returns DataFrame
duplicate_order_ids_returns = returns_df.duplicated(subset=['Order ID'])
num_duplicate_order_ids_returns = duplicate_order_ids_returns.sum()
print(f"Number of duplicate Order IDs in Returns DataFrame: {num_duplicate_order_ids_returns}")

# If duplicates exist, view them
if num_duplicate_order_ids_returns > 0:
    print("Duplicate Order IDs in Returns DataFrame:")
    print(returns_df[returns_df.duplicated(subset=['Order ID'], keep=False)].sort_values('Order ID'))

# Remove duplicate returns if any
if num_duplicate_order_ids_returns > 0:
    returns_df = returns_df.drop_duplicates()
    print(f"Dropped {num_duplicate_order_ids_returns} duplicate return records. New shape:", returns_df.shape)

"""# Data Conversion"""

# Check data types before conversion
print("Data Types Before Conversion:")
print(orders_df_cleaned.dtypes)

# Example: Convert 'Order Priority' to categorical
orders_df_cleaned['Order Priority'] = orders_df_cleaned['Order Priority'].astype('category')

# Convert 'Ship Mode' to category
orders_df_cleaned['Ship Mode'] = orders_df_cleaned['Ship Mode'].astype('category')

# Convert 'Segment' to category
orders_df_cleaned['Segment'] = orders_df_cleaned['Segment'].astype('category')

# Convert 'Region' to category
orders_df_cleaned['Region'] = orders_df_cleaned['Region'].astype('category')

# Convert 'Category' to category
orders_df_cleaned['Category'] = orders_df_cleaned['Category'].astype('category')

# Convert 'Sub-Category' to category
orders_df_cleaned['Sub-Category'] = orders_df_cleaned['Sub-Category'].astype('category')

# Check data types after conversion
print("\nData Types After Conversion:")
print(orders_df_cleaned.dtypes)

"""# Merging Datasets"""

# Merge Returns with Orders on 'Order ID'
orders_returns_df = orders_df_cleaned.merge(returns_df[['Order ID', 'Returned']], on='Order ID', how='left')

# Fill NaN in 'Returned' column with 'No' for orders that were not returned
orders_returns_df['Returned'] = orders_returns_df['Returned'].fillna('No')

# Confirm the merge
print("Orders with Returns Information:")
print(orders_returns_df[['Order ID', 'Returned']].head())

# Check the distribution of returned vs. not returned
return_counts = orders_returns_df['Returned'].value_counts()
print("\nReturn Counts:")
print(return_counts)

# Visualize the distribution
plt.figure(figsize=(6,4))
sns.countplot(x='Returned', data=orders_returns_df, palette='Set2')
plt.title('Distribution of Returned vs. Not Returned Orders')
plt.show()

"""# Checking for unique labels in categorical variablies"""

# Function to display unique values in a categorical column
def unique_values(df, column):
    print(f"Unique values in '{column}':")
    print(df[column].unique())
    print("\n")

# Check unique values in 'Ship Mode'
unique_values(orders_returns_df, 'Ship Mode')

# Check unique values in 'Segment'
unique_values(orders_returns_df, 'Segment')

# Check unique values in 'Region'
unique_values(orders_returns_df, 'Region')

# Check unique values in 'Category'
unique_values(orders_returns_df, 'Category')

# Check unique values in 'Sub-Category'
unique_values(orders_returns_df, 'Sub-Category')

# Check unique values in 'Order Priority'
unique_values(orders_returns_df, 'Order Priority')

# Example: Standardize 'Ship Mode' if inconsistencies are found
# orders_returns_df['Ship Mode'] = orders_returns_df['Ship Mode'].str.strip().str.title()

# Repeat similar standardization for other categorical columns as needed

"""# Descriptive Statistics"""

# Assuming 'orders_returns_df' is your cleaned and merged DataFrame

# 3.1 Descriptive Statistics for Numerical Variables
numerical_cols = orders_returns_df.select_dtypes(include=['int64', 'float64']).columns
print("Descriptive Statistics for Numerical Variables:\n")
print(orders_returns_df[numerical_cols].describe())

# 3.2 Descriptive Statistics for Categorical Variables
categorical_cols = orders_returns_df.select_dtypes(include=['object', 'category']).columns
print("\nDescriptive Statistics for Categorical Variables:\n")
for col in categorical_cols:
    print(f"Column: {col}")
    print(orders_returns_df[col].value_counts())
    print("\n")

"""# Visualizing the spread of Variables"""

# 3.3 Visual Summaries for Numerical Variables

# Set Seaborn style for better aesthetics
sns.set(style="whitegrid")

for col in numerical_cols:
    plt.figure(figsize=(8, 3))

    # Histogram with KDE
    plt.subplot(1, 2, 1)
    sns.histplot(orders_returns_df[col], kde=True, bins=30, color='skyblue')
    plt.title(f'Histogram of {col}')
    plt.xlabel(col)
    plt.ylabel('Frequency')

    # Box Plot
    plt.subplot(1, 2, 2)
    sns.boxplot(x=orders_returns_df[col], color='lightgreen')
    plt.title(f'Box Plot of {col}')
    plt.xlabel(col)

    plt.tight_layout()
    plt.show()

categorical_cols = [
    'Ship Mode',
    'Segment',
    'Region',
    'Category',
    'Sub-Category',
    'Order Priority',
    'Returned'
]

for col in categorical_cols:
    plt.figure(figsize=(5, 4))
    sns.countplot(
        y=orders_returns_df[col],
        order=orders_returns_df[col].value_counts().index,
        palette='Set3'
    )
    plt.title(f'Count Plot of {col}')
    plt.xlabel('Count')
    plt.ylabel(col)
    plt.show()

# 4.1 Correlation Matrix for Numerical Variables
plt.figure(figsize=(10, 8))
corr_matrix = orders_returns_df[numerical_cols].corr()
sns.heatmap(corr_matrix, annot=True, fmt=".2f", cmap='coolwarm')
plt.title('Correlation Matrix of Numerical Variables')
plt.show()

# Scatter Plot of Sales vs. Profit
plt.figure(figsize=(10, 6))
sns.scatterplot(x='Sales', y='Profit', data=orders_returns_df, alpha=0.3)
sns.regplot(x='Sales', y='Profit', data=orders_returns_df, scatter=False, color='red')
plt.title('Sales vs. Profit')
plt.xlabel('Sales')
plt.ylabel('Profit')
plt.show()

# Return Rates by Segment
return_segment = orders_returns_df.groupby(['Segment', 'Returned']).size().unstack()
return_segment.plot(kind='bar', stacked=True, figsize=(10,6), color=['green', 'red'])
plt.title('Return Rates by Segment')
plt.xlabel('Segment')
plt.ylabel('Number of Orders')
plt.legend(title='Returned', loc='upper right')
plt.show()

# Shipping Cost by Region (Top 10 Regions by Order Count)
top_regions = orders_returns_df['Region'].value_counts().nlargest(10).index
plt.figure(figsize=(12, 8))
sns.boxplot(x='Shipping Cost', y='Region', data=orders_returns_df[orders_returns_df['Region'].isin(top_regions)], palette='Set2')
plt.title('Shipping Cost by Top 10 Regions')
plt.xlabel('Shipping Cost')
plt.ylabel('Region')
plt.show()

# Profit by Category
plt.figure(figsize=(10, 6))
sns.boxplot(x='Profit', y='Category', data=orders_returns_df, palette='Set1')
plt.title('Profit by Category')
plt.xlabel('Profit')
plt.ylabel('Category')
plt.show()

# Return Rates by Sub-Category (Top 10 Sub-Categories by Order Count)
top_sub_categories = orders_returns_df['Sub-Category'].value_counts().nlargest(10).index
return_sub = orders_returns_df[orders_returns_df['Sub-Category'].isin(top_sub_categories)].groupby(['Sub-Category', 'Returned']).size().unstack()
return_sub.plot(kind='bar', stacked=True, figsize=(12,6), color=['green', 'red'])
plt.title('Return Rates by Top 10 Sub-Categories')
plt.xlabel('Sub-Category')
plt.ylabel('Number of Orders')
plt.legend(title='Returned', loc='upper right')
plt.show()

"""# Additional analysis

"""

# Calculate correlation coefficient
correlation = orders_returns_df['Sales'].corr(orders_returns_df['Profit'])
print(f"Correlation between Sales and Profit: {correlation:.2f}")

# Identify orders with negative profit
negative_profit = orders_returns_df[orders_returns_df['Profit'] < 0]
print(f"Number of orders with negative profit: {negative_profit.shape[0]}")

# Display some examples
print(negative_profit[['Order ID', 'Sales', 'Discount', 'Shipping Cost', 'Profit']].head())

# Calculate return rates
return_rates = orders_returns_df.groupby('Segment')['Returned'].value_counts(normalize=True).unstack()
print(return_rates)

# Plot return rates by segment
plt.figure(figsize=(8,6))
sns.barplot(x=return_rates.index, y='Yes', data=return_rates)
plt.title('Return Rate by Segment')
plt.xlabel('Segment')
plt.ylabel('Return Rate (%)')
plt.ylim(0, 0.2)  # Adjust based on actual rates
plt.show()

# Calculate summary statistics for Shipping Cost by Region
shipping_cost_summary = orders_returns_df.groupby('Region')['Shipping Cost'].describe()
print(shipping_cost_summary)

# Explore factors contributing to high shipping costs in top regions
high_cost_orders = orders_returns_df[orders_returns_df['Shipping Cost'] > orders_returns_df['Shipping Cost'].quantile(0.95)]
print(high_cost_orders[['Order ID', 'Region', 'Sales', 'Shipping Cost']].head())

# Calculate mean and median profit by category
profit_by_category = orders_returns_df.groupby('Category')['Profit'].agg(['mean', 'median', 'std'])
print(profit_by_category)

# Explore factors contributing to high profits in Technology
tech_high_profit = orders_returns_df[(orders_returns_df['Category'] == 'Technology') & (orders_returns_df['Profit'] > orders_returns_df['Profit'].quantile(0.95))]
print(tech_high_profit[['Order ID', 'Sales', 'Discount', 'Shipping Cost', 'Profit']].head())

# Calculate return rates for top 10 sub-categories
top_sub_categories = orders_returns_df['Sub-Category'].value_counts().nlargest(10).index
return_sub = orders_returns_df[orders_returns_df['Sub-Category'].isin(top_sub_categories)].groupby(['Sub-Category', 'Returned']).size().unstack()
return_sub['Return Rate (%)'] = return_sub['Yes'] / (return_sub['Yes'] + return_sub['No']) * 100
print(return_sub)

# Export the cleaned DataFrame to a CSV file
orders_returns_df.to_csv('cleaned_global_superstore.csv', index=False)

# Import the files module from google.colab
from google.colab import files

# Trigger the download of the CSV file
files.download('cleaned_global_superstore.csv')

# Import necessary libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# For model building
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve

# Load the cleaned dataset
# Assuming 'orders_returns_df' is already loaded and cleaned
# If not, load it using pd.read_csv or other relevant methods

# Encode the target variable
orders_returns_df['Returned_Label'] = orders_returns_df['Returned'].map({'Yes': 1, 'No': 0})

# Select relevant features for prediction
# Exclude high-cardinality or identifier variables as identified in EDA
features = [
    'Sales',
    'Quantity',
    'Discount',
    'Shipping Cost',
    'Ship Mode',
    'Segment',
    'Region',
    'Category',
    'Sub-Category',
    'Order Priority'
]

X = orders_returns_df[features]
y = orders_returns_df['Returned_Label']

# Encode categorical variables using one-hot encoding
X = pd.get_dummies(X, columns=['Ship Mode', 'Segment', 'Region', 'Category', 'Sub-Category', 'Order Priority'], drop_first=True)

# Feature Scaling for numerical variables
scaler = StandardScaler()
numerical_features = ['Sales', 'Quantity', 'Discount', 'Shipping Cost']
X[numerical_features] = scaler.fit_transform(X[numerical_features])

# Handle class imbalance using SMOTE (Synthetic Minority Over-sampling Technique)
from imblearn.over_sampling import SMOTE

smote = SMOTE(random_state=42)
X_resampled, y_resampled = smote.fit_resample(X, y)

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.3, random_state=42, stratify=y_resampled)

# Initialize the Random Forest Classifier
rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')

# Train the model
rf_classifier.fit(X_train, y_train)

# Make predictions on the test set
y_pred = rf_classifier.predict(X_test)
y_pred_proba = rf_classifier.predict_proba(X_test)[:,1]

# Classification Report
print("Classification Report:\n")
print(classification_report(y_test, y_pred))

# Confusion Matrix
plt.figure(figsize=(6,4))
sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='Blues', xticklabels=['No', 'Yes'], yticklabels=['No', 'Yes'])
plt.ylabel('Actual')
plt.xlabel('Predicted')
plt.title('Confusion Matrix')
plt.show()

# ROC AUC Score
roc_auc = roc_auc_score(y_test, y_pred_proba)
print(f"ROC AUC Score: {roc_auc:.2f}")

# ROC Curve
fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)
plt.figure(figsize=(8,6))
plt.plot(fpr, tpr, label=f'Random Forest (AUC = {roc_auc:.2f})')
plt.plot([0,1], [0,1], 'k--')  # Diagonal line
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc='lower right')
plt.show()

# Feature Importance
importances = rf_classifier.feature_importances_
feature_names = X.columns
feature_importances = pd.Series(importances, index=feature_names).sort_values(ascending=False)

# Plot Feature Importances
plt.figure(figsize=(12,8))
sns.barplot(x=feature_importances[:20], y=feature_importances.index[:20], palette='viridis')
plt.title('Top 20 Feature Importances')
plt.xlabel('Importance Score')
plt.ylabel('Feature')
plt.show()

# Display the top 10 important features
print("Top 10 Important Features:\n")
print(feature_importances.head(10))

